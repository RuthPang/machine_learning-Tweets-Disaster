# -*- coding: utf-8 -*-
"""TweetsDisaster.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iatEvCVFA7ZzTeX8wWFPSYgU6wuJ6_tU

##Loading Data
"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd
from sklearn import feature_extraction, linear_model, model_selection, preprocessing, utils

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

"""##DataPreprocess"""

train[train["target"]==0]["text"].values[1]
train[train["target"]==1]["text"].values[1]

#shuffle data
train=utils.shuffle(train, random_state=0)

#building vectors (tokens)
count_vectorizer = feature_extraction.text.CountVectorizer()
example_train_vectors=count_vectorizer.fit_transform(train["text"][:5])

print(example_train_vectors.todense().shape)
print(example_train_vectors[0].todense())
print(example_train_vectors[0])

train_vectors = count_vectorizer.fit_transform(train["text"])
test_vectors = count_vectorizer.transform(test["text"])

"""## Model"""

from sklearn.ensemble import VotingClassifier
from pandas.core.common import random_state
from sklearn.linear_model import LogisticRegression,SGDClassifier, RidgeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier,RandomForestClassifier

# ridge_clf = linear_model.RidgeClassifier(alpha=6.5)  #
# sgd_clf=linear_model.SGDClassifier(alpha=0.1)
# # log_clf=linear_model.LogisticRegression(C=1.5)
# lr = linear_model.LogisticRegression(max_iter=1500,C=0.25,penalty = 'l2',class_weight='balanced',solver = 'liblinear',intercept_scaling = 2)
# voting_clf=VotingClassifier(estimators=[('lr',lr),('sgd',sgd_clf),('ridge',ridge_clf)],voting='hard')


lr = LogisticRegression(C=0.125,multi_class='multinomial',random_state=1)
svm = SVC(probability=True,C=1.5)
rnd_clf = RandomForestClassifier(n_estimators=600,random_state=1)
voting_clf=VotingClassifier(estimators=[('lr',lr),('rnd',rnd_clf),('svm',svm)],voting='soft')

# scores = model_selection.cross_val_score(ridge_clf, train_vectors, train["target"], cv=3, scoring="f1")
# print(scores)
# scores = model_selection.cross_val_score(sgd_clf, train_vectors, train["target"], cv=3, scoring="f1")
# print(scores)
# score=model_selection.cross_val_score(lr,train_vectors,train["target"],cv=3,scoring="f1")
# print(score)
# score=model_selection.cross_val_score(voting_clf,train_vectors,train["target"],cv=3,scoring="f1")
# print(score)

scores = model_selection.cross_val_score(lr, train_vectors, train["target"], cv=3, scoring="f1")
print(scores)
scores = model_selection.cross_val_score(svm, train_vectors, train["target"], cv=3, scoring="f1")
print(scores)
scores = model_selection.cross_val_score(rnd_clf, train_vectors, train["target"], cv=3, scoring="f1")
print(scores)
scores = model_selection.cross_val_score(voting_clf, train_vectors, train["target"], cv=3, scoring="f1")
print(scores)

# Evaluate (confusion metrix)
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

voting_clf.fit(train_vectors, train["target"])
y_train_pred = voting_clf.predict(train_vectors)
print(confusion_matrix(train["target"],y_train_pred,labels=[0,1]))
print(precision_score(train["target"],y_train_pred))
print(recall_score(train["target"],y_train_pred))
f1_score(train["target"],y_train_pred)

sample_submission = pd.read_csv("sample_submission.csv")

sample_submission["target"] = ridge_clf.predict(test_vectors)

sample_submission.head()

sample_submission.to_csv("submission.csv", index=False)

from keras.layers import Input, Dense
from keras.models import Model
from keras.utils.vis_utils import plot_model
x = Input(shape=(32,))
y = Dense(16, activation='softmax')(x)
model = Model(x, y)
plot_model(model)
model.summary()